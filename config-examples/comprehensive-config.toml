# CodeWeaver MCP Server - Comprehensive Configuration Example
# This file demonstrates all available configuration options in the new v2.0 format
# Place this file as .code-weaver.toml in your project root, or rename and use as:
# - .local.code-weaver.toml (workspace local, highest precedence)
# - ~/.config/code-weaver/config.toml (user-level)

# Configuration metadata
_config_version = "2.0"

# =============================================================================
# VECTOR DATABASE BACKEND CONFIGURATION
# =============================================================================

[backend]
# Backend provider - supports multiple vector databases
provider = "qdrant"  # Options: qdrant, pinecone, chroma, weaviate, pgvector, milvus, elasticsearch

# Connection settings
url = "https://your-cluster.qdrant.io"  # Or use VECTOR_BACKEND_URL env var
api_key = "your-qdrant-api-key"         # Or use VECTOR_BACKEND_API_KEY env var
collection_name = "code-embeddings"

# Feature capabilities
enable_hybrid_search = true     # Enable hybrid dense + sparse search (qdrant, weaviate, milvus)
enable_sparse_vectors = true    # Enable sparse vector indexing for keyword search
enable_streaming = false        # Enable streaming for large operations

# Performance settings
batch_size = 100               # Batch size for vector operations
connection_timeout = 30.0      # Connection timeout in seconds
request_timeout = 60.0         # Request timeout in seconds
max_connections = 10           # Maximum concurrent connections

# Advanced settings
prefer_disk = false            # Store vectors on disk vs memory (if supported)
enable_failover = false        # Enable failover to replica URLs
replica_urls = []              # List of replica URLs for failover

# Provider-specific options (varies by backend)
[backend.provider_options]
# Qdrant-specific
grpc_port = 6334
prefer_grpc = true

# Pinecone-specific (uncomment if using Pinecone)
# environment = "us-west1-gcp"
# index_name = "code-embeddings"

# Weaviate-specific (uncomment if using Weaviate)
# timeout_config = [30.0, 60.0]  # [connection_timeout, read_timeout]

# =============================================================================
# EMBEDDING & RERANKING PROVIDER CONFIGURATION
# =============================================================================

[provider]
# Primary embedding provider
embedding_provider = "voyage"                    # Options: voyage, openai, cohere, sentence-transformers, huggingface
embedding_api_key = "your-voyage-api-key"       # Or use VOYAGE_API_KEY env var
embedding_model = "voyage-code-3"               # Provider-specific model name
embedding_dimension = 1024                      # Embedding dimension (auto-detected if not specified)
embedding_batch_size = 8                        # Batch size for embedding requests

# Reranking configuration
rerank_provider = "voyage"                       # Options: voyage, cohere (optional)
rerank_api_key = "your-voyage-api-key"          # Usually same as embedding API key
rerank_model = "voyage-rerank-2"                # Provider-specific rerank model

# Provider-specific settings
base_url = "https://api.voyageai.com/v1"        # Custom API endpoint (for OpenAI-compatible APIs)
custom_headers = {}                              # Additional HTTP headers

# Local model settings (for sentence-transformers, huggingface)
use_local = false                                # Use local models instead of API
device = "auto"                                  # Device: cpu, cuda, mps, auto
normalize_embeddings = true                     # Normalize embedding vectors

# Advanced provider settings
enable_caching = true                            # Enable response caching
cache_ttl_seconds = 3600                        # Cache time-to-live

# =============================================================================
# DATA SOURCES CONFIGURATION
# =============================================================================

[data_sources]
# Global data source settings
enabled = true                                   # Enable data source abstraction
default_source_type = "filesystem"              # Default source type for compatibility
max_concurrent_sources = 5                      # Maximum concurrent source operations

# Content processing settings
enable_content_deduplication = true             # Remove duplicate content across sources
content_cache_ttl_hours = 24                    # Content cache time-to-live
enable_metadata_extraction = true               # Extract metadata from content

# Primary file system source
[[data_sources.sources]]
type = "filesystem"
enabled = true
priority = 1
source_id = "main_codebase"

[data_sources.sources.config]
root_path = "."
use_gitignore = true
additional_ignore_patterns = [
    "node_modules", ".git", ".venv", "venv", "__pycache__",
    "target", "build", "dist", ".next", ".nuxt", "coverage",
    ".pytest_cache", ".mypy_cache", ".tox", "htmlcov"
]
max_file_size_mb = 1
batch_size = 8
enable_change_watching = false
change_check_interval_seconds = 60
patterns = [
    "**/*.py", "**/*.js", "**/*.ts", "**/*.tsx", "**/*.jsx",
    "**/*.go", "**/*.rs", "**/*.java", "**/*.cpp", "**/*.c",
    "**/*.h", "**/*.hpp", "**/*.cs", "**/*.php", "**/*.rb",
    "**/*.swift", "**/*.kt", "**/*.scala", "**/*.clj",
    "**/*.md", "**/*.rst", "**/*.txt"
]

# Git repository source (example - disabled by default)
[[data_sources.sources]]
type = "git"
enabled = false
priority = 2
source_id = "external_library"

[data_sources.sources.config]
repository_url = "https://github.com/example/library.git"
branch = "main"
local_clone_path = "/tmp/codeweaver_repos/external_library"
auto_pull = true
pull_interval_minutes = 60
track_file_history = false
include_branches = ["main", "develop"]
exclude_paths = ["docs/", "examples/"]

# API documentation source (example - disabled by default)
[[data_sources.sources]]
type = "api"
enabled = false
priority = 3
source_id = "rest_api_docs"

[data_sources.sources.config]
api_type = "rest"
base_url = "https://api.example.com"
endpoints = ["/docs", "/schema", "/openapi.json"]
auth_type = "bearer"
bearer_token = "your-api-token"
schema_discovery = true
include_documentation = true
max_response_size = 1000000

# =============================================================================
# LEGACY CONFIGURATION (for backward compatibility)
# =============================================================================

[embedding]
# Legacy embedding configuration - synced with provider.* settings
provider = "voyage"
api_key = "your-voyage-api-key"
model = "voyage-code-3"
dimension = 1024
batch_size = 8
rerank_provider = "voyage"
rerank_model = "voyage-rerank-2"

[qdrant]
# Legacy Qdrant configuration - synced with backend.* settings
url = "https://your-cluster.qdrant.io"
api_key = "your-qdrant-api-key"
collection_name = "code-embeddings"
enable_sparse_vectors = true

# =============================================================================
# SHARED CONFIGURATION
# =============================================================================

[chunking]
max_chunk_size = 1500
min_chunk_size = 50
max_file_size_mb = 1

# Language-specific chunking settings
[chunking.language_settings.python]
max_chunk_size = 2000
function_extraction = true

[chunking.language_settings.javascript]
max_chunk_size = 1800
include_comments = true

[indexing]
use_gitignore = true
additional_ignore_patterns = [
    "node_modules", ".git", ".venv", "venv", "__pycache__",
    "target", "build", "dist", ".next", ".nuxt", "coverage"
]

# Auto-reindexing on file changes
enable_auto_reindex = false
watch_debounce_seconds = 2.0

# Performance settings
batch_size = 8
max_concurrent_files = 10

[rate_limiting]
# Provider-specific rate limits
voyage_requests_per_minute = 100
voyage_tokens_per_minute = 1000000
openai_requests_per_minute = 5000
openai_tokens_per_minute = 1000000
cohere_requests_per_minute = 1000
cohere_tokens_per_minute = 500000

# Backend rate limits
qdrant_requests_per_second = 100
pinecone_requests_per_second = 50
weaviate_requests_per_second = 200

# Exponential backoff settings
initial_backoff_seconds = 1.0
max_backoff_seconds = 60.0
backoff_multiplier = 2.0
max_retries = 5

[server]
server_name = "code-weaver-mcp"
server_version = "2.0.0"
log_level = "INFO"

# Performance settings
enable_request_logging = false
max_search_results = 50
enable_metrics = false
metrics_port = 8080

# Security settings
enable_cors = true
allowed_origins = ["*"]
enable_rate_limiting = true